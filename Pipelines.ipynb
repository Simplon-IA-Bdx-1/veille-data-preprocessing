{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Preprocessing avec Scikit Learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, MinMaxScaler, Normalizer, QuantileTransformer, FunctionTransformer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pandas import DataFrame, read_csv\n",
    "from pprint import pprint\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Les methodes de preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Toutes les méthodes de preprocessing suivent le même processus:   \n",
    "1- On crée une instance de la méthode.   \n",
    "2- On fit cette instance sur un dataset avec .fit()  \n",
    "3- On applique la même transformation sur n'importe quel dataset avec .transform()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## SimpleImputer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SimpleImputer sert à compléter les valeurs manquantes.\n",
    "Les paramètres principaux de cette méthode sont:\n",
    "- missing_value: Valeur à remplacer\n",
    "- strategy:\n",
    "    - \"mean\" (default): remplace toutes les missing_values par la moyenne de la colonne. Seulement sur les features numériques.\n",
    "    - \"median\": remplace toutes les missing_values par la médiane de la colonne. Seulement sur les features numériques.\n",
    "    - \"most_frequent\": remplace toutes les missing_values par la valeur la plus présente dans la colonne. Seulement sur les features numériques.\n",
    "    - \"constant\": remplace toutes les missing_values par la valeur du paramètre fill_value\n",
    "- fill_value: valeur qui remplace les missing_values si strategy = \"constant\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## OneHotEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OneHotEncoder est utilisé pour encoder les variables catégorielles en variables numériques binaires.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X =[['Cat'], ['Dog'], ['Python']]\n",
    "X1 = [['Dog'], ['Python'], ['Cat'], ['Cat'], ['Python']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Encodeur Simple"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "#### \"categories\": \n",
    "    - \"auto\" détermine automatiquement les différentes catégories en se basant sur celes présentes dans le dataset passé en fit. \n",
    "    - On peut également lui passer une liste de catégories.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "encoder = OneHotEncoder()\n",
    "encoder.fit(X)\n",
    "encoder.transform(X1).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Supprimer une colonne pour éviter la colinéarité"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### \"drop\": drop un des features\n",
    "    - \"first\": drop le premier feature\n",
    "    -  On peut aussi lui préciser quel feature dropper.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "encoder_drop = OneHotEncoder(drop=\"first\")\n",
    "encoder_drop.fit(X)\n",
    "encoder_drop.transform(X1).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Gérer des valeurs inconnues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### \"handle_unknown\": \n",
    "    - \"ignore\": ne peut être utilisé si drop est précisé. Si l'encoder rencontre une valeur inconnue dans le dataset à transformer ,il remplira toutes les colonnes créées avec des zéros.\n",
    "    - \"error\": l'encodeur lèvera une erreur lorsqu'il rencontrera une nouvelle valeur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1.append(['Anaconda'])\n",
    "encoder_handle_unknown = OneHotEncoder(handle_unknown=\"ignore\")\n",
    "encoder_handle_unknown.fit(X)\n",
    "encoder_handle_unknown.transform(X1).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les différents modules Sklearn de preprocessing sont disponibles à :\n",
    "https://scikit-learn.org/stable/modules/classes.html#module-sklearn.preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le StandardScaler transforme les données pour les présenter sous une distribution Gaussienne, avec une moyenne de zéro et une unit variance. C'est important de l'utiliser pour des modèles type SVM, RBF Kernel (qui utilise la distance euclidienne), mais aussi les régularisation L1 et L2 des modèles linéaires.\n",
    "\n",
    "Les valeurs manquantes ne sont pas regardées pendant l'entraînement, et sont resittuées comme tel lors de la transformation.\n",
    "\n",
    "Il existe deux paramètres importants qui sont True par défaut :\n",
    "**with_mean** : centre les données avant de les scaler.\n",
    "**with_std** : scale les données avec l'écart type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.125  9.   ]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-1.18321596, -1.18321596],\n",
       "       [-0.50709255, -0.50709255],\n",
       "       [ 0.16903085,  0.16903085],\n",
       "       [ 1.52127766,  1.52127766]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = [[-1, 2], \n",
    "        [-0.5, 6], \n",
    "        [0, 10], \n",
    "        [1, 18]]\n",
    "\n",
    "data0 = data\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(data)\n",
    "print(scaler.mean_)\n",
    "scaler.transform(data0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### MinMaxScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Permet de transposer les valeur d'un dataframe sur un range choisie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.  , 0.  ],\n",
       "       [0.25, 0.25],\n",
       "       [0.5 , 0.5 ],\n",
       "       [1.  , 1.  ]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1 = data\n",
    "scaler = MinMaxScaler() #feature_range = [2,4])\n",
    "scaler.fit_transform(data1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Normalizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Permet d'appliquer de la normalisation sur un dataframe.<br />\n",
    "Fonctionne avec Dense et spicy.matrix.<br />\n",
    "‘l1’, ‘l2’, ‘max’"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.33333333,  0.66666667],\n",
       "       [-0.07692308,  0.92307692],\n",
       "       [ 0.        ,  1.        ],\n",
       "       [ 0.05263158,  0.94736842]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2 = data\n",
    "normalizer = Normalizer(norm = 'l1')\n",
    "normalizer.fit_transform(data2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Quantile Transformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Permet de générer des quantiles à partir d'un dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data3 = data\n",
    "quantiletransformer = QuantileTransformer(n_quantiles=3, random_state=0)\n",
    "quantiletransformer.fit_transform(data3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Function Transformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Permet d'appliquer n'importe quelle fonction sur un dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data4 = data\n",
    "functiontransformer = FunctionTransformer(np.log1p)\n",
    "functiontransformer.fit_transform(data4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "## Pipeline pour les features catégorielles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pipeline prend en parametres une liste de tuples (nom, transform) qui définie une séquence de transformations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_pipe = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder())\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Les pipelines forment une arborescence de méthodes et de paramêtres.\n",
    "- Les pipelines exposent l'ensemble des paramètres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_pipe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Les paramètres sont préfixés par le nom donné dans le tuple.\n",
    "- On peut utiliser get_param pour obtenir les paramètres.\n",
    "- On peut utiliser set_param pour les modifier.\n",
    "- Attention, il y'a 2 underscore!\n",
    "- Chaque hyperparamètre pourra être optimisé."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(categorical_pipe.get_params())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Setters et getters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "categorical_pipe.get_params()['imputer__strategy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "categorical_pipe.set_params(imputer__strategy='constant', imputer__fill_value='NA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_pipe.set_params(imputer__strategy='most_frequent');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Pipeline pour les features numériques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_pipe = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## ColumnTransformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ColumnTransformer permet de combiner des traitements differents pour chaque groupe de colonnes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_columns=['Fence', 'CentralAir']\n",
    "num_columns=['GrLivArea', 'LotFrontage', 'LotArea']\n",
    "\n",
    "preprocess_pipe = ColumnTransformer([\n",
    "    ('cat', categorical_pipe, cat_columns),\n",
    "    ('num', numeric_pipe, num_columns)])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Pipeline complet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pipeline complet avec preprocessing et modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearRegression()\n",
    "\n",
    "full_pipe = Pipeline(\n",
    "    [('pp', preprocess_pipe),\n",
    "    ('reg', model)]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Exemple sur House Prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = read_csv('./train.csv')\n",
    "test_df = read_csv('./test.csv')\n",
    "X = train_df[['GrLivArea', 'LotFrontage', 'LotArea', 'Fence', 'CentralAir']]\n",
    "y = train_df[['SalePrice']]\n",
    "X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "En une seule ligne:\n",
    "- Preprocessing des features numériques et catégorielles\n",
    "- Entrainement du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_pipe.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Preprocessing\n",
    "- Prediction sur le validation set et le test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = full_pipe.predict(X_train)\n",
    "y_valid_pred = full_pipe.predict(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "df = DataFrame(data={'value':y_valid['SalePrice'], 'predicted':y_valid_pred.reshape(-1,)}, index=y_valid.index)\n",
    "plt.figure(figsize=(15,10))\n",
    "sns.scatterplot(x='value',y='predicted', data=df )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Sources\n",
    "\n",
    "- https://www.kaggle.com/lucabasa/understand-and-use-a-pipeline\n",
    "- https://scikit-learn.org/stable/modules/classes.html#module-sklearn.preprocessing\n",
    "\n",
    "# Aller plus loin\n",
    "- Définir des transformations pour des dataframes pandas\n",
    "    - https://ramhiser.com/post/2018-04-16-building-scikit-learn-pipeline-with-pandas-dataframe/"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Diaporama",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
